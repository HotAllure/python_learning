{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hand shape image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 initial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constant\n",
    "IMAGE_SIZE = 40\n",
    "COLOR_BYTE = 3\n",
    "CATEGORY_NUM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting hand image\n",
    "\n",
    "def load_handimage(path):\n",
    "    files = glob.glob(os.path.join(path, '*/*.png'))\n",
    "    \n",
    "    #allocate for image and label\n",
    "    images = np.ndarray((len(files), IMAGE_SIZE,IMAGE_SIZE, COLOR_BYTE),\n",
    "                       dtype = np.uint8)\n",
    "    labels = np.ndarray(len(files), dtype=np.int)\n",
    "    \n",
    "    for idx, file in enumerate(files):\n",
    "        #load image\n",
    "        image = io.imread(file)\n",
    "        images[idx] = image\n",
    "        \n",
    "        #get label name (â€»dir name represents label)\n",
    "        label = os.path.split(os.path.dirname(file))[-1]\n",
    "        labels[idx] = label\n",
    "    \n",
    "    #follow other datasets' format in scikit-learn\n",
    "    flat_data = images.reshape((-1, IMAGE_SIZE*IMAGE_SIZE*COLOR_BYTE))\n",
    "    images = flat_data.view()\n",
    "    return datasets.base.Bunch(data=flat_data,\n",
    "                              target=labels.astype(np.int),\n",
    "                              target_names=np.arange(CATEGORY_NUM),\n",
    "                              images=images,\n",
    "                              DESCR=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='./data/my_learn8'\n",
    "test_path='./data/my_test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "\n",
    "#load dataset\n",
    "train = load_handimage(train_path)\n",
    "test = load_handimage(test_path)\n",
    "\n",
    "#instantiate model and fit\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(train.data, train.target)\n",
    "\n",
    "#evaluate perfornace with test data\n",
    "predicted = classifier.predict(test.data)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='./data/my_learn10'\n",
    "test_path='./data/other_test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "train = load_handimage(train_path)\n",
    "test = load_handimage(test_path)\n",
    "\n",
    "#instantiate model and fit\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(train.data, train.target)\n",
    "\n",
    "#evaluate perfornace with test data\n",
    "predicted = classifier.predict(test.data)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 use more dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/m01', './data/m02', './data/m03', './data/m04', './data/m04c', './data/m05', './data/m06', './data/m07', './data/m08', './data/m09', './data/m10', './data/m11', './data/m12', './data/m13', './data/m14', './data/m15', './data/m16']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "data_dir = './data'\n",
    "\n",
    "path_list = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
    "path_list = path_list[:-4]\n",
    "\n",
    "print(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  ['./data/m01', './data/m05', './data/m06', './data/m07']\n",
      "train ['./data/m02', './data/m03', './data/m04', './data/m08', './data/m09', './data/m10', './data/m11', './data/m12', './data/m13', './data/m14', './data/m15', './data/m16']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_test = 4 # number of test directory\n",
    "\n",
    "'''\n",
    "# option : randomize directory\n",
    "indice = np.arange(len(path_list))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indice)\n",
    "\n",
    "paths_for_test = sorted(np.array(path_list)[indice[:n_test]])\n",
    "paths_for_train = sorted(np.array(path_list)[indice[n_test:]])\n",
    "'''\n",
    "\n",
    "#set directories explicitly to follow textbook\n",
    "paths_for_test =['./data/m01', './data/m05', './data/m06', './data/m07']\n",
    "paths_for_train =['./data/m02', './data/m03', './data/m04', './data/m08', './data/m09', './data/m10', \n",
    "                './data/m11', './data/m12', './data/m13', './data/m14', './data/m15', './data/m16']\n",
    "\n",
    "print('test ', paths_for_test)\n",
    "print('train', paths_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train dataset\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "for path in paths_for_train:\n",
    "    d = load_handimage(path)\n",
    "    train_data.append(d.data)\n",
    "    train_label.append(d.target)\n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_label = np.concatenate(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify by SVM\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "#instantiate model\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "#fit\n",
    "classifier.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ./data/m01 ###\n",
      "Accuracy: 0.725\n",
      "Classification_Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.97      0.85       100\n",
      "          1       0.57      0.39      0.46       100\n",
      "          2       0.55      0.53      0.54       100\n",
      "          3       0.74      0.58      0.65       100\n",
      "          4       0.72      0.88      0.79       100\n",
      "          5       0.94      1.00      0.97       100\n",
      "\n",
      "avg / total       0.71      0.72      0.71       600\n",
      "\n",
      "\n",
      "### ./data/m05 ###\n",
      "Accuracy: 0.625\n",
      "Classification_Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      1.00      0.76       100\n",
      "          1       0.55      0.41      0.47       100\n",
      "          2       0.54      0.38      0.45       100\n",
      "          3       0.57      0.74      0.65       100\n",
      "          4       0.64      0.72      0.68       100\n",
      "          5       1.00      0.50      0.67       100\n",
      "\n",
      "avg / total       0.65      0.62      0.61       600\n",
      "\n",
      "\n",
      "### ./data/m06 ###\n",
      "Accuracy: 0.59\n",
      "Classification_Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.34      0.95      0.51       100\n",
      "          1       0.71      0.36      0.48       100\n",
      "          2       0.33      0.09      0.14       100\n",
      "          3       0.77      0.83      0.80       100\n",
      "          4       0.83      0.34      0.48       100\n",
      "          5       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.66      0.59      0.56       600\n",
      "\n",
      "\n",
      "### ./data/m07 ###\n",
      "Accuracy: 0.6266666666666667\n",
      "Classification_Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.79      0.81       100\n",
      "          1       0.59      0.57      0.58       100\n",
      "          2       0.35      0.50      0.41       100\n",
      "          3       0.27      0.08      0.12       100\n",
      "          4       0.71      0.87      0.78       100\n",
      "          5       0.83      0.95      0.89       100\n",
      "\n",
      "avg / total       0.60      0.63      0.60       600\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of model with each test dataset\n",
    "\n",
    "for path in paths_for_test:\n",
    "    d = load_handimage(path)\n",
    "    predicted = classifier.predict(d.data)\n",
    "    \n",
    "    print('### {0} ###'.format(path))\n",
    "    print('Accuracy:', metrics.accuracy_score(d.target, predicted))\n",
    "    print('Classification_Report:\\n{0}\\n'.format(metrics.classification_report(d.target, predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=\"Red\">original part : follow the discussion on textbook with working code</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### check : the reason why data/m01 got better performance than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor path in paths_for_test:\\n    d = load_handimage(path)\\n    images_2 = d.images[d.target==2]\\n    images_2 = images_2.reshape(-1 ,IMAGE_SIZE, IMAGE_SIZE, COLOR_BYTE)\\n    \\n    print('====== {0} ======'.format(path))\\n    \\n    fig = plt.figure(figsize=(40,40),dpi=100)\\n    \\n    for i, image in enumerate(images_2[:num_images]):\\n    \\n        plt.subplot(num_images/5,5,i+1)\\n        plt.imshow(image)\\n        \\n        ax = plt.gca()\\n        ax.tick_params(labelbottom=False, bottom=False)\\n        ax.tick_params(labelleft=False, left=False)\\n        \\n    plt.tight_layout()\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 50\n",
    "\n",
    "#uncomment below if you want to show test dataset \n",
    "'''\n",
    "for path in paths_for_test:\n",
    "    d = load_handimage(path)\n",
    "    images_2 = d.images[d.target==2]\n",
    "    images_2 = images_2.reshape(-1 ,IMAGE_SIZE, IMAGE_SIZE, COLOR_BYTE)\n",
    "    \n",
    "    print('====== {0} ======'.format(path))\n",
    "    \n",
    "    fig = plt.figure(figsize=(40,40),dpi=100)\n",
    "    \n",
    "    for i, image in enumerate(images_2[:num_images]):\n",
    "    \n",
    "        plt.subplot(num_images/5,5,i+1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(labelbottom=False, bottom=False)\n",
    "        ax.tick_params(labelleft=False, left=False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result : images in data/m01 tend to be more regulated than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# prepare train dataset\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "#set list of path explicitly\n",
    "path_list =['./data/m01', './data/m02', './data/m03', './data/m04', './data/m05', './data/m06', './data/m07',\n",
    "            './data/m08', './data/m09', './data/m10', './data/m11', './data/m12', './data/m13', './data/m14',\n",
    "            './data/m15', './data/m16']\n",
    "groups = []\n",
    "\n",
    "for i, path in enumerate(path_list):\n",
    "    d = load_handimage(path)\n",
    "    train_data.append(d.data)\n",
    "    train_label.append(d.target) \n",
    "    groups.append([i+1 for _ in range(len(d.data))])\n",
    "    \n",
    "train_data = np.concatenate(train_data)\n",
    "train_label = np.concatenate(train_label)\n",
    "groups = np.concatenate(groups)\n",
    "\n",
    "#instantiate model\n",
    "classifier = svm.LinearSVC()\n",
    "scores = cross_val_score(classifier, train_data, train_label, groups=groups, cv=16)\n",
    "   \n",
    "print('16 fold cross validation score ')\n",
    "for path, score in zip(path_list, scores):\n",
    "    print('{0} : {1}'.format(path, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
